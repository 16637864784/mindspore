get_auto_parallel_context(attr_key)

    根据key获取自动并行的配置。

    参数：
        attr_key (str)：配置的key。

    返回：
        根据key返回配置的值。

    异常：
        ValueError：输入key不在自动并行的配置列表中。

Class mindspore.context.ParallelMode

    并行模式。

    有五种并行模式，分别是STAND_ALONE、DATA_PARALLEL、HYBRID_PARALLEL、SEMI_AUTO_PARALLEL和AUTO_PARALLEL。
    默认值：STAND_ALONE。

    - STAND_ALONE：单卡模式。
    - DATA_PARALLEL：数据并行模式。
    - HYBRID_PARALLEL：手动实现数据并行和模型并行。
    - SEMI_AUTO_PARALLEL：半自动并行模式。
    - AUTO_PARALLEL：自动并行模式。

    MODE_LIST：表示所有支持的并行模式的列表。
    

reset_auto_parallel_context()

    重置自动并行的配置为默认值。

    - device_num：1。
    - global_rank：0。
    - gradients_mean：False。
    - gradient_fp32_sync：True。
    - parallel_mode：'stand_alone'。
    - auto_parallel_search_mode：'dynamic_programming'。
    - parameter_broadcast：False。
    - strategy_ckpt_load_file：''。
    - strategy_ckpt_save_file：''。
    - full_batch：False。
    - enable_parallel_optimizer：False。
    - pipeline_stages：1。
    
set_auto_parallel_context(**kwargs)

    配置自动并行，仅在Ascend和GPU上有效。

    应在init之前配置自动并行。

    注：
        配置时，必须输入配置的名称。
        如果某个程序具有不同并行模式下的任务，则需要再为下一个任务设置新的并行模式之前，调用reset_auto_parallel_context()接口来重置配置。
        若要设置或更改并行模式，必须在创建任何Initializer之前调用接口，否则，在编译网络时，可能会出现RuntimeError。

    某些配置适用于特定的并行模式，有关详细信息，请参见下表：

    ===========================  ===========================
    Common                       AUTO_PARALLEL
    ===========================  ===========================
    device_num                   gradient_fp32_sync
    global_rank                  loss_repeated_mean
    gradients_mean               auto_parallel_search_mode
    parallel_mode                strategy_ckpt_load_file
    all_reduce_fusion_config     strategy_ckpt_save_file
    enable_parallel_optimizer    dataset_strategy
               \                 pipeline_stages
               \                 grad_accumulation_step
    ===========================  ===========================

    参数：
        device_num (int)：表示可用设备的编号，必须在【1,4096】范围中。默认值：1。
        global_rank (int)：表示全局秩的ID，必须在【0,4095】范围中。默认值：0。
        gradients_mean (bool)：表示是否在梯度的allreduce后执行平均算子。
                     stand_alone不支持gradients_mean。默认值：False。
        gradient_fp32_sync (bool)：在FP32中运行gradients的allreduce。stand_alone、data_parallel和hybrid_parallel不支持gradient_fp32_sync。默认值：True。
        parallel_mode (str)：有五种并行模式，分别是stand_alone、data_parallel、hybrid_parallel、semi_auto_parallel和auto_parallel。默认值：stand_alone。

                     - stand_alone：单卡模式。

                     - data_parallel：数据并行模式。

                     - hybrid_parallel：手动实现数据并行和模型并行。

                     - semi_auto_parallel：半自动并行模式。

                     - auto_parallel：自动并行模式。
        auto_parallel_search_mode (str)：表示有两种策略搜索模式，分别是recursive_programming和dynamic_programming。默认值：dynamic_programming。

                     - recursive_programming：表示双递归搜索模式。

                     - dynamic_programming：表示动态规划搜索模式。
        parameter_broadcast (bool)：表示在训练前是否广播参数。在训练之前，为了使所有设备的网络初始化参数值相同，请将设备0上的参数广播到其他设备。不同并行模式下的参数广播不同。
                     在data_parallel模式下，除layerwise_parallel属性为True的参数外，所有参数都会被广播。在Hybrid_parallel、semi_auto_parallel和auto_parallel模式下，分段参数不参与广播。默认值：False。
        strategy_ckpt_load_file (str)：表示用于加载并行策略checkpoint的路径。默认值：''。
        strategy_ckpt_save_file (str)：表示用于保存并行策略checkpoint的路径。默认值：''。
        full_batch (bool)：如果在auto_parallel模式下加载整个batch数据集，则此参数应设置为True。默认值：False。目前不建议使用该接口，建议使用dataset_strategy来替换它。
        dataset_strategy (Union[str, tuple])：表示数据集分片策略。默认值：data_parallel。
                       dataset_strategy="data_parallel"等于full_batch=False，dataset_strategy="full_batch"等于full_batch=True。对于通过模型并列策略加载到网络的数据集，如ds_stra ((1, 8)、(1, 8))，需要使用set_auto_parallel_context(dataset_strategy=ds_stra)。
        enable_parallel_optimizer (bool)：这是一个开发中的特性，它可以为数据并行训练对权重更新计算进行分片，以节省时间和内存。目前，自动和半自动并行模式支持Ascend和GPU中的所有优化器。数据并行模式仅支持Ascend中的`Lamb`和`AdamWeightDecay`。默认值：False。
        all_reduce_fusion_config (list)：通过参数索引设置allreduce 融合策略。仅支持ReduceOp.SUM和HCCL_WORLD_GROUP/NCCL_WORLD_GROUP。没有默认值。如果不设置，则关闭算子融合。
        pipeline_stages (int)：设置pipeline并行的阶段信息。这表明了设备如何单独分布在pipeline上。所有的设备将被划分为pipeline_stags个阶段。
                        目前，这只能在启动semi_auto_parallel模式的情况下使用。默认值：1。
        grad_accumulation_step (int)：在自动和半自动并行模式下设置梯度的累积step。
                        其值应为正整数。默认值：1。

    异常：
        ValueError：输入key不是自动并行上下文中的属性。

    样例：
        >>> context.set_auto_parallel_context(device_num=8)
        >>> context.set_auto_parallel_context(global_rank=0)
        >>> context.set_auto_parallel_context(gradients_mean=True)
        >>> context.set_auto_parallel_context(gradient_fp32_sync=False)
        >>> context.set_auto_parallel_context(parallel_mode="auto_parallel")
        >>> context.set_auto_parallel_context(auto_parallel_search_mode="dynamic_programming")
        >>> context.set_auto_parallel_context(parameter_broadcast=False)
        >>> context.set_auto_parallel_context(strategy_ckpt_load_file="./strategy_stage1.ckpt")
        >>> context.set_auto_parallel_context(strategy_ckpt_save_file="./strategy_stage1.ckpt")
        >>> context.set_auto_parallel_context(dataset_strategy=((1, 8), (1, 8)))
        >>> context.set_auto_parallel_context(enable_parallel_optimizer=False)
        >>> context.set_auto_parallel_context(all_reduce_fusion_config=[8, 160])
        >>> context.set_auto_parallel_context(pipeline_stages=2)
