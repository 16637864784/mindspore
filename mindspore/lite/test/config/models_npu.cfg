mobilenet_v1_0.25_128.tflite 2.5
mobilenet_v1_0.25_160.tflite 2.5
mobilenet_v1_0.25_192.tflite 1.5
mobilenet_v1_0.25_224.tflite 2
mobilenet_v1_0.5_128.tflite 2
mobilenet_v1_0.5_160.tflite 2
mobilenet_v1_0.5_192.tflite 2.5
mobilenet_v1_0.5_224.tflite 2
mobilenet_v1_0.75_128.tflite 3
mobilenet_v1_0.75_160.tflite 3
mobilenet_v1_0.75_192.tflite 3.5
mobilenet_v1_0.75_224.tflite 1.5
mobilenet_v1_1.0_128.tflite 6
mobilenet_v1_1.0_160.tflite 2
mobilenet_v1_1.0_192.tflite 6
mobilenet_v1_1.0_224.tflite 2.5
mobilenet_v2_1.0_224.tflite 2.5
squeezenet.tflite 2.5
inception_resnet_v2.tflite 2
inception_v3.tflite 1
inception_v4.tflite 0.5
efficientnet_lite0_fp32_2.tflite 1
efficientnet_lite1_fp32_2.tflite 1
efficientnet_lite2_fp32_2.tflite 1
efficientnet_lite3_fp32_2.tflite 1
efficientnet_lite4_fp32_2.tflite 1
deeplabv3_1_default_1.tflite 2.5
6c_seg_nomean_20200610 1.5
ml_video_edit_person_divison 0.5
ml_video_edit_style_transfer_autoportrait.onnx 9
ml_video_edit_style_transfer_candy.onnx 11
ml_video_edit_style_transfer_gongnongbing.onnx 10.5
ml_video_edit_style_transfer_starry.onnx 11
porseg_tmp.onnx;2 1
ml_video_edit_Mnet 1.5
ml_video_edit_hairSeg_have_imageProcessLayer_interpTo145 0.5
ml_video_edit_img_segment 1
ml_video_edit_video_segment_gauss_adaptis_part1 2
ml_video_edit_generate_filter.pb 1
ml_video_edit_img_segment_adaptise.pb;2 0.5
ml_video_edit_video_segment_gauss_adaptis_part2.pb;2 10
ml_video_edit_person_divison_pic 0.5
ml_video_edit_person_divison_video;2 13
ml_video_edit_judge.onnx 5
ml_video_edit_vignet.onnx 0.5
hdc_Face_Aesthetic_MTI_Aesthetic 0.5
hdc_Face_Emotion_MTI_Aesthetic.onnx 30
hdc_Face_Landmark5_MTI_Aesthetic.onnx 0.5
hdc_Image_Aesthetic_MTI_Aesthetic.onnx 0.5
hdc_mobilenet_1w_class.onnx 10
hdc_resnet_1w_class.onnx 5
#hdc_age_medium 6
hdc_contour_pose_128 4
hdc_emotion 0.5
hdc_fivembnet 0.5
hdc_isface 0.5
hdc_mobilenetface 4
#hdc_retinaface #too many subgraphs
hdc_resnet 3
ml_video_edit_detect 1
ml_video_edit_hairSeg_have_imageProcessLayer_interpTo145_20210121 0.5
ml_video_edit_have_imageProcessLayer_interpTo145_20201015 0.5
ml_video_edit_MnetN367_extract_1010_pay 0.5
ml_video_edit_reid 0.5
ml_video_edit_v10_best_model_nomean_20200723 8
hdc_ocr_attention.onnx 0.5 #too many subgraphs
# hdc_ocr_detect.onnx 30 #too many subgraphs
ml_edu_kit_hand_detection.onnx 1
ml_edu_kit_hand_key_position.onnx 2
ml_video_edit_oneclick_adaptis.pb;3 2.4
densenet.tflite 3
resnet_v2_101_299.tflite 1
ml_video_edit_enhance.pb 2
ml_video_edit_video_segment_gauss_adaptis_part2_pb2tflite.tflite;2 10
ml_video_edit_img_segment_adaptise_pb2tflite.tflite;2 0.5
#the fifth value of the ml_video_edit_imitate_filter.onnx's output is very small (10-5).
ml_video_edit_imitate_filter.onnx 200
hdc_mobilenet_1w_class.onnx 20
hdc_age_medium 504
posenet_mobilenet_float_075_1_default_1.tflite 14
nasnet_mobile.tflite 1
ml_video_edit_art_generate.onnx 0.5
ml_video_edit_art_transfer.onnx;3 3
ml_video_edit_enhance_update_tmp.onnx 0.5
ml_video_edit_art_generate_20210513.onnx 0.5
ml_video_edit_art_transfer_20210513.onnx;3 0.5
ml_video_edit_hair_dyeing_segmodel_v3 0.5
ml_video_edit_makeup_mobilenetv203.onnx 2
ml_video_edit_hairline_segmentation;3 0.5
ml_video_edit_hair_dyeing_migrate_v2.onnx;4 0.5
#not support control flow model with npu
#ml_audio_kit_encoder_v5.pb;6;1:1,32:1,32:1,32:1:1,32
fsr_270_mindspore.pb 1
fsr_360_mindspore.pb 1
fsr_720_mindspore.pb 1
ml_motion_capture_spin-mobile;4 1.5
ml_motion_capture_spin-res50;4 1
ml_motion_capture_spin-res50-poolingnoceilmode;4 1
ml_video_edit_hair_dyeing_migrate_v2_fix.onnx;4 1.5
ml_motion_capture_yolov3-spp-deploy_ddk_prune 1
ml_video_edit_seg_320 0.5
hiai_model_0909_kd_rot_ps_softmax.tflite 4
hiai_chinese_english_recognize_model_float32.tflite 3
hiai_bigmodel_ghost_2_1_no_normalized_no_trans_tflite.tflite 2
hiai_bigmodel_ghost_5_1_no_normalized_no_trans_tflite.tflite 3
hiai_cn_recognize_modify_padv2.tflite 5
hiai_model_normalize_object_scene_ps_20200519.tflite 14
mtk_AADB_HADB_MBV2_model_fp32.tflite 1.5
#mtk_AADB_HADB_MBV3_model_fp32.tflite 2.5
mtk_model_ckpt.tflite 5
#mtk_age_gender.tflite
#mtk_model_face_dress.tflite;1:input
mtk_face_features_v1.tflite 8
mnasnet_1.3_224.tflite;1:input 2
deeplabv3_257_mv_gpu.tflite;1:sub_7 1
multi_person_mobilenet_v1_075_float.tflite;1:sub_2 6
ide_label_base.tflite;1:input 11
#large precision bias error
#ide_label_retrained.tflite;1:input_1
#ml_ei_headpose.tflite;1:input_1
#ml_ei_landmark.tflite;1:input_image
mnist.tflite;1:conv2d_input 1.5
#mobilenet.tflite;1:conv2d_input
#resnet.tflite;1:input_1
scan_hms_angle1.tflite;1:normalized_input_image_tensor 1.5
scan_hms_detect.tflite;1:normalized_input_image_tensor 41
hiai_latin_ocr.tflite;1:input_0 32
hiai_latin_ocr_1.tflite;1:input_0 5.5
#ml_ocr_jk.tflite;1:input_0
#nasnet_mobile.tflite;1:input
#nasnet_large.tflite;1:input
#model_emotions_0727_nosoftmax.tflite;1:input
#ml_ocr_latin.tflite;1:input_0
hiai_PoseEstimation_Pcm.tflite;1:image 12
#large precision bias error
#hiai_ssd_mobilenetv2_object.tflite;1:image_tensor
hiai_cv_focusShootOCRModel_02.tflite;1:input_0 5
hiai_cv_poseEstimation.tflite;1:Image 37
mtk_model_normalize_object_scene_ps_20200519_f16.tflite;1:input_0 3
#mtk_age_gender_fp16.tflite;1:img
#mtk_model_face_dress_fp16.tflite;1:img
#mtk_AADB_HADB_MBV2_model_f16.tflite;1:input_0
#mtk_AADB_HADB_MBV3_model_f16.tflite;1:input_0
#mtk_model_emotions_0725_fp16.tflite;1:input
mtk_face_features_v1_fp16.tflite;1:input 4
#siteAI_digcom_AI_ECN.tflite;1:input_expansion
siteAI_digcom_g2v_keras.tflite;1:conv2d_1_input 2
#siteAI_trans_nonlinear.tflite;1:features_placeholder
siteAI_trans_tcpclassify.tflite;1:conv2d_1_input 2.5
#siteAI_wireless_depress_w.tflite;1:x-input
#siteAI_wireless_restore_w.tflite;1:x-input
#magenta_arbitrary-image-stylization-v1-256_fp16_prediction_1.tflite;1:style_image
#ml_object_detect.tflite;1:input/input_data
#ml_object_detect_1.tflite;1:input/input_data
hiai_cpu_face_emotion.tflite;1:input_0 1.5
#hiai_cpu_face_gazing.tflite;1:input_0
hiai_cpu_face_headpose.tflite;1:input_0 1.5
hiai_humanDetection.tflite;1:normalized_input_image_tensor 150
hiai_cv_focusShootOCRModel_08.tflite;1:input 4
#ml_face_openclose.tflite;1:input
hiai_face_model_npu.tflite;1:input_0 3
hiai_ctpn_feature_map.tflite;1:input_image 2
hiai_cv_labelDetectorModel_v2.tflite;1:input_0 10
hiai_cv_labelDetectorModel_v4.tflite;1:input_0 1
hiai_dress_detect.tflite;1:data 1
#hiai_cv_saliencyDetectorModel.tflite;1:image_tensor
hiai_frozen_inference_graph.tflite;1:image_tensor 2.5
#hiai_ghostnet.tflite;1:input
#hiai_iMaxDN_RGB.tflite;1:input
#hiai_iMaxSR_RGB.tflite;1:input
hiai_label_and_video.tflite;1:input_0 4.5
#hiai_lm_inference_graph.tflite;1:image_tensor
mnasnet_0.50_224_1_metadata_1.tflite;1:input 3.5
mnasnet_0.75_224_1_metadata_1.tflite;1:input 3
mnasnet_1.0_128_1_metadata_1.tflite;1:input 2.5
mnasnet_1.0_160_1_metadata_1.tflite;1:input 2
mnasnet_1.0_192_1_metadata_1.tflite;1:input 2
mnasnet_1.0_224_1_metadata_1.tflite;1:input 1.5
mnasnet_1.0_96_1_metadata_1.tflite;1:input 1.5
#lite-model_on_device_vision_classifier_popular_us_products_V1_1.tflite;1:uint8_image_input
#lite-model_on_device_vision_classifier_popular_wine_V1_1.tflite;1:uint8_image_input
#lite-model_deeplabv3-mobilenetv2_dm05-float16_1_default_1.tflite;1:sub_7
#lite-model_deeplabv3-mobilenetv2-float16_1_default_1.tflite;1:sub_7
lite-model_east-text-detector_fp16_1.tflite;1:input_images 460
#lite-model_cartoongan_fp16_1.tflite;1:input_photo
lite-model_arbitrary-image-stylization-inceptionv3_fp16_predict_1.tflite;1:style_image 1
#gts_detect_5k_tf115.tflite;1:normalized_input_image_tensor
#mtk_isface.tflite;1:data
#mtk_landmark.tflite;1:img
#mtk_new_detect.tflite;1:input
#mtk_pose.tflite;1:input
#mtk_model_emotions_0727_nosoftmax.tflite;1:input
mtk_model_normalize_object_scene_ps_20200826_f32_no_softmax.tflite;1:input_0 32
mtk_276landmark_0913.tflite;1:input 4
#mtk_face_recognition.tflite;1:input
#mtk_convert_model.tflite;1:data
#smartreply.tflite;1:input_sentence
mindspore_text_classification_tflite.tflite;1:base_input 3
# ml_location.tflite
#ml_text_correction.tflite;1:hed_input
#ml_pic_shopping.tflite;1:images
#ml_vision_guide_detection3_pb2tflite.tflite;1:input/input_data
#ml_vision_guide_detection1_pb2tflite.tflite;1:input/input_data
#ml_pic_shopping_pb2tflite.tflite;1:images
#ml_ocr_jk_pb2tflite.tflite;1:input_0
#ml_ocr_latin_pb2tflite.tflite;1:input_0
scan_hms_angle_pb2tflite.tflite;1:normalized_input_image_tensor 2.5
scan_hms_detect_pb2tflite.tflite;1:normalized_input_image_tensor 110
#ml_location.tflite;1:inputs
#ml_face_openclose_tflite.tflite;1:input
#ml_object_detect_pb2tflite.tflite;1:input/input_data
Q_AADB_HADB_MBV2_model.tflite;1:input_0 2.5
#Q_convert.tflite;1:input
#Q_crnn_ori_75w_slim_norm_pb2tflite.tflite;1:input_0
#Q_crnn_ori_v2_405001_notrans_nopre_pb2tflite.tflite;1:input_0
#Q_crnn_screen_slim400w_more_20w_pb2tflite.tflite;1:input_0
Q_dila-small-mix-full-fineturn-390000-nopixel-nosigmoid_tflite.tflite;1:input 2
Q_focusocr_cn_recog.tflite;1:input_0 8
Q_focusocr_jk_recog.tflite;1:input_0 6.5
Q_inception-249970-672-11-16_pb2tflite.tflite;1:input 3
#Q_isface.tflite;1:data
#Q_landmark.tflite;1:img
Q_language_model_hrmini_Q4_b4_17w.tflite;1:input_0 51
#Q_new_detect.tflite;1:input
Q_object_scene.tflite;1:input_0 2.5
Q_pose.tflite;1:input 1
#ml_ei_landmark_pb2tflite.tflite;1:input_image
unet_mbv2_05_104pts.tflite;1:input 4.5
hiai_AADB_HADB_MBV2_model_f16.tflite;1:input_0 1
hiai_AADB_HADB_MBV2_model_fp32.tflite;1:input_0 2.5
#hiai_detect_curve_model_float32.tflite;1:input
hiai_detectmodel_06_23_960_480_1180700.tflite;1:input 2.5
hiai_detectmodel_desnet_256_128_64_32.tflite;1:input 13
lite-model_aiy_vision_classifier_food_V1_1.tflite;1:input 15
lite-model_disease-classification_1.tflite;1:mobilenetv2_1_00_224_input 30
#lite-model_models_mushroom-identification_v1_1.tflite;1:input
#smartreply_1_default_1.tflite;1:input_sentence
#text_classification.tflite;1:embedding_input
#Q_detect_fpn_add_inception-1448650.tflite;1:input
Q_hand_0812_pb2tflite.tflite;1:input 8
#bloom_landmark.tflite;1:img
Q888_age_gender_orderd.tflite;1:input 5.5
#Q888_face_dress_mv3y.tflite;1:input
Q888_HADB_AADB_MBV2_model_fp32.tflite;1:input_0 1
#Q888_landmark.tflite;1:img
Q888_pose.tflite;1:input 1.5
Q888_lapa158_unet_0924.tflite;1:input 4.5
#Q888_isface.tflite;1:data
#Q888_new_detect.tflite;1:input
Q888_model_normalize_object_scene_ps_20200826_f32_no_softmax.tflite;1:input_0 1.5
